{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Database Notebook\n",
    "\n",
    "![MNIST](https://cdn-images-1.medium.com/max/1200/1*7HmSJOABTcRzWMVOB3fJlA.png)\n",
    "\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Mnist Dataset\n",
    "Because of how common this dataset is relating to image classification it is accessasible from many sources but in this notebook I will be using Tensorflow and Keras to download or access the MNIST dataset directly from their API.Therefore, I will start with the following two lines to import tensorflow and MNIST dataset under the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation\n",
    "Because the dataset has  a training set of 60,000 and a test set of 10,000 examples we need to separate these two groups into \n",
    "train and test groups also separated the labels and the images. x_train and x_test parts contain greyscale RGB codes (from 0 to 255) while y_train and y_test parts contains labels from 0 to 9 which represents which number they actually are.To see this numbers we can display them using matplotlib.When we run the code we will get an output of greyscale visualization of the RGB codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1487956ef28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 100 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) \n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the shape of the dataset by using shape attribute of numpy array\n",
    "The result being 60,000 being the amount of images in the train dataset and 28 representing the size of the images 28x28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping & Normalizing the images\n",
    "We need 4-dims numpy arrays to be able to use the Keras API but however our array is 3-dims so to fix that we must normalize our data as it is always required when it comes to neural network models.So we can get that by diving the RGB codes to 255 (Max RGB - Min RGB) as outline and done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Convolutional Neural Network\n",
    "In this notebook I will demonstrate how to build a neural network using high level Keras API for the reason being it is the simplest and most straightforward approach but other APIs that can be used are Layers, Keras, and Estimators.\n",
    "Below I will import the Sequential Model from Keras and add Conv2D, MaxPooling, Flatten, Dropout, and Dense layers.\n",
    "Basically that will create an non-optimized empty Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling and Fitting the Model\n",
    "it is time to set an optimizer with a given loss function which uses a metric. Then, we can fit the model by using our train data by using the following code below.\n",
    "You can experiment with different optimizers to experiment but in this case I will be using the adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 37s 624us/step - loss: 0.2131 - acc: 0.9355\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 36s 603us/step - loss: 0.0884 - acc: 0.97250s - loss: 0.0885 - acc: 0.97\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.0627 - acc: 0.9801\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 36s 594us/step - loss: 0.0473 - acc: 0.9844\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 37s 614us/step - loss: 0.0380 - acc: 0.9874\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 35s 587us/step - loss: 0.0317 - acc: 0.9894\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 38s 633us/step - loss: 0.0277 - acc: 0.99022s - loss: 0.0272 - acc: 0.99 \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 36s 608us/step - loss: 0.0230 - acc: 0.9922\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 37s 617us/step - loss: 0.0198 - acc: 0.9934\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 37s 619us/step - loss: 0.0192 - acc: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148795156d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 154us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05720065278664606, 0.9864]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "https://www.katacoda.com/basiafusinska/courses/tensorflow-getting-started/tensorflow-mnist-beginner\n",
    "    \n",
    "http://cs231n.github.io/convolutional-networks\n",
    "    \n",
    "https://keras.io/datasets/\n",
    "    \n",
    "https://en.wikipedia.org/wiki/MNIST_database  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
